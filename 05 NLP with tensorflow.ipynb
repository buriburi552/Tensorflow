{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce325b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv(r'D:\\1jupyter\\Datasets\\NLP disaster\\train.csv')\n",
    "test_df = pd.read_csv(r'D:\\1jupyter\\Datasets\\NLP disaster\\test.csv')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dff877a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>3796</td>\n",
       "      <td>destruction</td>\n",
       "      <td>NaN</td>\n",
       "      <td>So you have a new weapon that can cause un-ima...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>3185</td>\n",
       "      <td>deluge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>7769</td>\n",
       "      <td>police</td>\n",
       "      <td>UK</td>\n",
       "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>191</td>\n",
       "      <td>aftershock</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aftershock back to school kick off was great. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>9810</td>\n",
       "      <td>trauma</td>\n",
       "      <td>Montgomery County, MD</td>\n",
       "      <td>in response to trauma Children of Addicts deve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      keyword               location  \\\n",
       "2644  3796  destruction                    NaN   \n",
       "2227  3185       deluge                    NaN   \n",
       "5448  7769       police                     UK   \n",
       "132    191   aftershock                    NaN   \n",
       "6845  9810       trauma  Montgomery County, MD   \n",
       "\n",
       "                                                   text  target  \n",
       "2644  So you have a new weapon that can cause un-ima...       1  \n",
       "2227  The f$&amp;@ing things I do for #GISHWHES Just...       0  \n",
       "5448  DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...       1  \n",
       "132   Aftershock back to school kick off was great. ...       0  \n",
       "6845  in response to trauma Children of Addicts deve...       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_shuffled = train_df.sample(frac=1, random_state=42) \n",
    "train_df_shuffled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "154036bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training samples: 7613\n",
      "Total test samples: 3263\n",
      "Total samples: 10876\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total training samples: {len(train_df)}\")\n",
    "print(f\"Total test samples: {len(test_df)}\")\n",
    "print(f\"Total samples: {len(train_df) + len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81a1ea95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "I was taught at school in the 1970s that piracy slavery and suicide-bombing were purely historical. No one then expected them to re-occur\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "Petition/No Medals for 1890 Massacre Justice for Wounded Knee Killings of Native Americans! http://t.co/UilPg8i1ev http://t.co/m9pXTo2kwW\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "70 years since we annihilated 100000 people instantly and became aware that we have the ability to annihilate the whole of humanity\n",
      "\n",
      "---\n",
      "\n",
      "Target: 0 (not real disaster)\n",
      "Text:\n",
      "@_DANGdaddy the sirens are telling you to get ready to TURN UP???????? http://t.co/qAQqrJv9gU\n",
      "\n",
      "---\n",
      "\n",
      "Target: 1 (real disaster)\n",
      "Text:\n",
      "KATUNews: #SR14 remains closed as brush fire burns 1700 acres: http://t.co/QposKp3MWj #LiveOnK2 http://t.co/mTQjsvupwy\n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random_index = random.randint(0, len(train_df)-5) \n",
    "for row in train_df_shuffled[[\"text\", \"target\"]][random_index:random_index+5].itertuples():\n",
    "  _, text, target = row\n",
    "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
    "  print(f\"Text:\\n{text}\\n\")\n",
    "  print(\"---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ee3e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_sentences, val_sentences, train_labels, val_labels = train_test_split(\n",
    "    train_df_shuffled[\"text\"].to_numpy(),\n",
    "    train_df_shuffled[\"target\"].to_numpy(),\n",
    "    test_size=0.1, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "915b9032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6851, 6851, 762, 762)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences), len(train_labels), len(val_sentences), len(val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d2635bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
       "        'Imagine getting flattened by Kurt Zouma',\n",
       "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
       "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
       "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
       "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
       "        'destroy the free fandom honestly',\n",
       "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
       "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
       "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
       "       dtype=object),\n",
       " array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1], dtype=int64))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences[:10], train_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ec3f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=None,\n",
    "                                    standardize='lower_and_strip_punctuation',\n",
    "                                    split='whitespace',\n",
    "                                    ngrams=None,\n",
    "                                    output_mode='int',\n",
    "                                    output_sequence_length=None)\n",
    "                                    #pad_to_max_tokens=True) if using max_tokens\n",
    "                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e098dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2d37e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab_length = 10000\n",
    "max_length = 15\n",
    "\n",
    "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
    "                                    output_mode='int',\n",
    "                                    output_sequence_length=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46847a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer.adapt(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1be48492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words in vocab: 10000\n",
      "most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
      "leat common words: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
     ]
    }
   ],
   "source": [
    "words_in_vocab = text_vectorizer.get_vocabulary()\n",
    "print(f'words in vocab: {len(words_in_vocab)}')\n",
    "print(f'most common words: {words_in_vocab[:5]}')\n",
    "print(f'leat common words: {words_in_vocab[-5:]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bea5bdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.embedding.Embedding at 0x23b59136070>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(42)\n",
    "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length,\n",
    "                                      output_dim=128,\n",
    "                                      embeddings_initializer='uniform',\n",
    "                                      input_length=max_length,\n",
    "                                      name='embedding')\n",
    "\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cecfc849",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06f0915e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;tfidf&#x27;, TfidfVectorizer()), (&#x27;clf&#x27;, MultinomialNB())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('clf', MultinomialNB())])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model0 = Pipeline([\n",
    "    ('tfidf',TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "model0.fit(train_sentences,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "809a0340",
   "metadata": {},
   "outputs": [],
   "source": [
    "score0 = model0.score(val_sentences,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb72f1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7926509186351706"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09b7e4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred0 = model0.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e78d04b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06995883",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import helper_functions as hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89df7a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[386  28]\n",
      " [130 218]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83       414\n",
      "           1       0.89      0.63      0.73       348\n",
      "\n",
      "    accuracy                           0.79       762\n",
      "   macro avg       0.82      0.78      0.78       762\n",
      "weighted avg       0.81      0.79      0.79       762\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(val_labels,pred0))\n",
    "print(classification_report(val_labels,pred0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3202da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 79.26509186351706,\n",
       " 'precision': 0.8111390004213173,\n",
       " 'recall': 0.7926509186351706,\n",
       " 'f1': 0.7862189758049549}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hf.calculate_results(y_true=val_labels,y_pred=pred0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70a1d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='input_layer')\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid', name='output_layer')(x)\n",
    "\n",
    "model1 = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c529d112",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3796a8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(loss='binary_crossentropy', \n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607dda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "history1 = model1.fit(x=train_sentences,y=train_labels,epochs=5,\n",
    "                      validation_data=(val_sentences,val_labels),\n",
    "                      callbacks=[hf.create_tensorboard_callback(dir_name='logs',\n",
    "                                                                experiment_name='nlp_model1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29640ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d493f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_prob_pred = model1.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2e02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_preds = tf.squeeze(tf.round(model1_prob_pred))\n",
    "model1_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bb57a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model1_results = hf.calculate_results(val_labels, model1_preds)\n",
    "model1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ceadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bfd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_weights = model1.get_layer('embedding').get_weights()[0]\n",
    "embed_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266c111f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "out_v = io.open('vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open('metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index, word in enumerate(words_in_vocab):\n",
    "  if index == 0:\n",
    "    continue  # skip 0, it's padding.\n",
    "  vec = embed_weights[index]\n",
    "  out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "  out_m.write(word + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d803a250",
   "metadata": {},
   "source": [
    "# RNN "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaf1f97",
   "metadata": {},
   "source": [
    "### model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccfdfbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(units=64)(x)\n",
    "#x = tf.keras.layers.Dense(units=64, activation='relu')(x) can add\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model2 = tf.keras.Model(inputs, outputs, name='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02490086",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e9bd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "history2 = model2.fit(x=train_sentences, y=train_labels, epochs=5,\n",
    "                      validation_data=(val_sentences, val_labels),\n",
    "                      callbacks=[hf.create_tensorboard_callback(dir_name='logs',\n",
    "                                                     experiment_name='nlp_model2')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1a9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.evaluate(val_sentences,val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9e046f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_pred_prob = model2.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0321d3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_pred = tf.squeeze(tf.round(model2_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b66154",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_results = hf.calculate_results(val_labels,model2_pred)\n",
    "model2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6d0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.LSTM(units=64, return_sequences=True)(x)\n",
    "x = tf.keras.layers.LSTM(units=64)(x)\n",
    "x = tf.keras.layers.Dense(units=64, activation='relu')(x) \n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model2_test = tf.keras.Model(inputs, outputs, name='LSTM')\n",
    "\n",
    "model2_test.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "hist2_test = model2.fit(x=train_sentences, y=train_labels, epochs=5,\n",
    "                        validation_data=(val_sentences, val_labels),\n",
    "                        callbacks=[hf.create_tensorboard_callback(dir_name='logs',\n",
    "                                                     experiment_name='nlp_model2_test')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74362ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2_test.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c6864c",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd6cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "inputs = tf.keras.layers.Input(shape=(1,), dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.GRU(units=64,return_sequences=True)(x)\n",
    "x = tf.keras.layers.GRU(64)(x)\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model3 = tf.keras.Model(inputs, outputs, name='GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c744697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])\n",
    "\n",
    "hist3 = model3.fit(x=train_sentences, y=train_labels, epochs=5,\n",
    "                        validation_data=(val_sentences, val_labels),\n",
    "                        callbacks=[hf.create_tensorboard_callback(dir_name='logs',\n",
    "                                                     experiment_name='nlp_model3')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd470644",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3_pred_probs = model3.predict(val_sentences)\n",
    "model3_pred = tf.squeeze(tf.round(model3_pred_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0445b3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.calculate_results(val_labels, model3_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd66602",
   "metadata": {},
   "source": [
    "### Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913b0a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(1,), name='input_shape', dtype='string')\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(units=64, return_sequences=True))(x)\n",
    "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=64))(x)\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid', name='output_layer')(x)\n",
    "model4 = tf.keras.Model(inputs, outputs, name='bidirectional')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f497cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41ff817",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c55798",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist4 = model4.fit(train_sentences, train_labels,\n",
    "           epochs=5, validation_data=(val_sentences, val_labels),\n",
    "           callbacks=[hf.create_tensorboard_callback(dir_name='logs', experiment_name='bidirectional_nlp')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0179a240",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2976da39",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4_probs = model4.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ce1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0c6bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4_preds = tf.squeeze(tf.round(model4_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1cfc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c504ec76",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.calculate_results(y_true=val_labels, y_pred=model4_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b93746",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(1,), name='input_layer', dtype=tf.string)\n",
    "x = text_vectorizer(inputs)\n",
    "x = embedding(x)\n",
    "x = tf.keras.layers.Conv1D(filters=64, kernel_size=5, activation='relu', strides=1, padding='valid')(x)\n",
    "x = tf.keras.layers.GlobalMaxPool1D()(x)\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid', name='output_layer')(x)\n",
    "model5 = tf.keras.Model(inputs,outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3505f436",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651f3af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d13b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist5 = model5.fit(train_sentences,\n",
    "                   train_labels,\n",
    "                   epochs=5,\n",
    "                   validation_data=(val_sentences, val_labels),\n",
    "                   callbacks=[hf.create_tensorboard_callback(dir_name='logs',experiment_name='nlp_conv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bbc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5.evaluate(val_sentences, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16354a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5_probs = model5.predict(val_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68db8296",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5_preds = tf.squeeze(tf.round(model5_probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model5_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a391c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.calculate_results(y_pred=model5_preds,y_true=val_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3735d488",
   "metadata": {},
   "source": [
    "### Transfer Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79ce1f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c1388e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d968ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name='USE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00652b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = Sequential()\n",
    "model6.add(sentence_encoder_layer)\n",
    "model6.add(Dense(units=64, activation='relu'))\n",
    "model6.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fca3a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model6.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5869d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model6.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.function(jit_compile=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bffb74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist6 = model6.fit(train_sentences,\n",
    "                   train_labels,\n",
    "                   epochs=5,\n",
    "                   validation_data=(val_sentences, val_labels),\n",
    "                   callbacks=[hf.create_tensorboard_callback(dir_name='logs',\n",
    "                                                             experiment_name='nse_nlp')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f053d0",
   "metadata": {},
   "source": [
    "### using 10 percent data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2bb59ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train10_per = train_df_shuffled[['text','target']].sample(frac=0.1, random_state=42)\n",
    "train_sentences10_per = train10_per['text']\n",
    "train_label10_per = train10_per['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8729e139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(761, 761)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sentences10_per), len(train_label10_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9ebdb241",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7 = Sequential()\n",
    "sentence_encoder_layer = hub.KerasLayer('https://tfhub.dev/google/universal-sentence-encoder/4',\n",
    "                                        input_shape=[],\n",
    "                                        dtype=tf.string,\n",
    "                                        trainable=False,\n",
    "                                        name='USE')\n",
    "model7.add(sentence_encoder_layer)\n",
    "model7.add(Dense(units=64, activation='relu'))\n",
    "model7.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe7bcc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model7.compile(loss='binary_crossentropy',\n",
    "               optimizer='Adam',\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77d5ca72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving TensorBoard log files to: logs/10percent data/20220806-172629\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nJIT compilation failed.\n\t [[{{node EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup/mod}}]] [Op:__inference_train_function_14375]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hist7 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel7\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_sentences10_per\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mtrain_label10_per\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_sentences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_labels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mhf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_tensorboard_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdir_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlogs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                                             \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m10percent data\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mUnknownError\u001b[0m: Graph execution error:\n\nJIT compilation failed.\n\t [[{{node EncoderDNN/EmbeddingLookup/EmbeddingLookupUnique/embedding_lookup/mod}}]] [Op:__inference_train_function_14375]"
     ]
    }
   ],
   "source": [
    "hist7 = model7.fit(train_sentences10_per, \n",
    "                   train_label10_per,\n",
    "                   epochs=5,\n",
    "                   validation_data=(val_sentences, val_labels),\n",
    "                   callbacks=[hf.create_tensorboard_callback(dir_name='logs',\n",
    "                                                             experiment_name='10percent data')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65169ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
